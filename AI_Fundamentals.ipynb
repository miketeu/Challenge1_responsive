{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miketeu/Challenge1_responsive/blob/main/AI_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Package Imports"
      ],
      "metadata": {
        "id": "9MGy-U9UOxsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05VOwYmiOtOC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import re\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Example"
      ],
      "metadata": {
        "id": "B83WAS9DO2JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"A clumsy British woman awkwardly navigates her career, family pressure, and embarrassing love life while keeping a brutally honest diary of wine soaked regrets.\",\n",
        "    \"An old man reads emotional diary entries about young love, heartbreak, emotional growth, and two wildly different people who fall in and out of love.\",\n",
        "    \"A rich orphan develops bat-themed PTSD and takes it out on a mentally ill clown, using gadgets, suits, and intense voice work.\",\n",
        "    \"An old boat crashes and love dies because two people canâ€™t share a wooden door, while class tension sinks along with the romance.\",\n",
        "    \"A man wears a metal suit to cope with his trauma, invents dangerous tech, and builds laser weapons while dealing with his ego and wealth.\",\n",
        "    \"Talking toys develop existential dread when their child loses interest in playing with them, questioning loyalty, friendship, and shelf life.\",\n",
        "    \"A rat controls a French man by pulling his hair, cooks gourmet food, and challenges the kitchen hierarchy through teamwork and hygiene violations.\",\n",
        "    \"An ice lady sings one song and causes a seasonal climate disaster, learns self-acceptance, and accidentally becomes queen of emotional repression.\",\n",
        "    \"A short-sighted child defeats an evil snake man with the power of love, friendship, and conveniently-timed magical plot armour.\",\n",
        "    \"A time-traveling teen nearly kisses his mother to save a rock concert, breaks the timeline, and invents 1980s pop culture by accident.\"\n",
        "]"
      ],
      "metadata": {
        "id": "wkr0scZ6Oy-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split each description into word/\"tokens\" + remove punctuation\n",
        "doc_words = [\n",
        "    [re.sub(r'[^\\w\\s]', '', word.lower()) for word in doc.split()]\n",
        "    for doc in documents\n",
        "]\n",
        "print(doc_words)\n",
        "print(len(doc_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgBly4ZAPIvo",
        "outputId": "a9b8c625-27de-4eeb-d439-a6955349aa71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['a', 'clumsy', 'british', 'woman', 'awkwardly', 'navigates', 'her', 'career', 'family', 'pressure', 'and', 'embarrassing', 'love', 'life', 'while', 'keeping', 'a', 'brutally', 'honest', 'diary', 'of', 'wine', 'soaked', 'regrets'], ['an', 'old', 'man', 'reads', 'emotional', 'diary', 'entries', 'about', 'young', 'love', 'heartbreak', 'emotional', 'growth', 'and', 'two', 'wildly', 'different', 'people', 'who', 'fall', 'in', 'and', 'out', 'of', 'love'], ['a', 'rich', 'orphan', 'develops', 'batthemed', 'ptsd', 'and', 'takes', 'it', 'out', 'on', 'a', 'mentally', 'ill', 'clown', 'using', 'gadgets', 'suits', 'and', 'intense', 'voice', 'work'], ['an', 'old', 'boat', 'crashes', 'and', 'love', 'dies', 'because', 'two', 'people', 'cant', 'share', 'a', 'wooden', 'door', 'while', 'class', 'tension', 'sinks', 'along', 'with', 'the', 'romance'], ['a', 'man', 'wears', 'a', 'metal', 'suit', 'to', 'cope', 'with', 'his', 'trauma', 'invents', 'dangerous', 'tech', 'and', 'builds', 'laser', 'weapons', 'while', 'dealing', 'with', 'his', 'ego', 'and', 'wealth'], ['talking', 'toys', 'develop', 'existential', 'dread', 'when', 'their', 'child', 'loses', 'interest', 'in', 'playing', 'with', 'them', 'questioning', 'loyalty', 'friendship', 'and', 'shelf', 'life'], ['a', 'rat', 'controls', 'a', 'french', 'man', 'by', 'pulling', 'his', 'hair', 'cooks', 'gourmet', 'food', 'and', 'challenges', 'the', 'kitchen', 'hierarchy', 'through', 'teamwork', 'and', 'hygiene', 'violations'], ['an', 'ice', 'lady', 'sings', 'one', 'song', 'and', 'causes', 'a', 'seasonal', 'climate', 'disaster', 'learns', 'selfacceptance', 'and', 'accidentally', 'becomes', 'queen', 'of', 'emotional', 'repression'], ['a', 'shortsighted', 'child', 'defeats', 'an', 'evil', 'snake', 'man', 'with', 'the', 'power', 'of', 'love', 'friendship', 'and', 'convenientlytimed', 'magical', 'plot', 'armour'], ['a', 'timetraveling', 'teen', 'nearly', 'kisses', 'his', 'mother', 'to', 'save', 'a', 'rock', 'concert', 'breaks', 'the', 'timeline', 'and', 'invents', '1980s', 'pop', 'culture', 'by', 'accident']]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of times the word 'diary' appears in each description - try changing the word & see what happens!\n",
        "for words in doc_words:\n",
        "  term_count = words.count('diary')\n",
        "  print(term_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxu5iRv6QqLT",
        "outputId": "f194917b-4096-4cbd-996d-62e400b18629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we divide by length of the particular film description to get TF\n",
        "for words in doc_words:\n",
        "  term_count = words.count('diary')\n",
        "  tf_value = term_count/len(words)\n",
        "  print(tf_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmDssWRjP5TH",
        "outputId": "a33fadb7-71e3-4031-dcdb-6bae7c59cf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.041666666666666664\n",
            "0.04\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df of specific word 'diary'\n",
        "df = sum(1 for words in doc_words if 'diary' in words)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DswngChQaFO",
        "outputId": "103fa1dd-0c27-47c6-bace-dc7642985fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# idf of specific word 'diary'\n",
        "num_docs = 10\n",
        "idf = math.log(num_docs / df)\n",
        "print(idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F806e2iJSaP3",
        "outputId": "11b5f165-fdad-478b-e39c-15b78a54bd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6094379124341003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf-idf for 'diary' within each document\n",
        "for words in doc_words:\n",
        "  term_count = words.count('diary')\n",
        "  tf_value = term_count/len(words)\n",
        "  tfidf = tf_value * idf\n",
        "  print(tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRv_d8bRSwPP",
        "outputId": "f451f477-9ed5-476b-b865-6dfedd6ebe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0670599130180875\n",
            "0.064377516497364\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's put it all together with multiple words at a time"
      ],
      "metadata": {
        "id": "gfW2NLgqUFvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define words of interest\n",
        "terms = [\"and\", \"love\", \"diary\"]\n",
        "\n",
        "# Compute Term Frequency (TF)\n",
        "tf = {}\n",
        "for term in terms:\n",
        "    tf[term] = []\n",
        "    for words in doc_words:\n",
        "        term_count = words.count(term)\n",
        "        tf_value = term_count / len(words)  # Frequency of term in document\n",
        "        tf[term].append(tf_value)\n",
        "\n",
        "# Compute Document Frequency (DF)\n",
        "df = {}\n",
        "for term in terms:\n",
        "    df[term] = sum(1 for words in doc_words if term in words)\n",
        "\n",
        "# Compute Inverse Document Frequency (IDF)\n",
        "num_docs = len(documents)\n",
        "idf = {term: math.log(num_docs / df[term]) for term in terms}\n",
        "\n",
        "# Compute TF-IDF\n",
        "tfidf = {}\n",
        "for term in terms:\n",
        "    tfidf[term] = [tf[term][i] * idf[term] for i in range(num_docs)]\n",
        "\n",
        "# Print TF-IDF values\n",
        "for term in terms:\n",
        "    print(f\"TF-IDF for '{term}': {tfidf[term]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR1QB8k-TJpo",
        "outputId": "684d8480-19aa-47f9-caf8-d718f3692c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF for 'and': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "TF-IDF for 'love': [0.03817878049475646, 0.07330325854993242, 0.0, 0.039838727472789354, 0.0, 0.0, 0.0, 0.0, 0.04822582799337658, 0.0]\n",
            "TF-IDF for 'diary': [0.0670599130180875, 0.064377516497364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine similarity for document 1 and 2"
      ],
      "metadata": {
        "id": "uvj0hkUqVzHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose & group values by index (doc)\n",
        "num_docs = len(next(iter(tfidf.values())))\n",
        "document_vectors = []\n",
        "for i in range(num_docs):\n",
        "    vector = [tfidf[word][i] for word in tfidf]\n",
        "    document_vectors.append(vector)\n",
        "# Document_vectors[i] is a vector for doc i\n",
        "print(document_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAcKb9ZWV1az",
        "outputId": "f2415172-5071-4a5c-c2ce-bef2b0d4223b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0, 0.03817878049475646, 0.0670599130180875], [0.0, 0.07330325854993242, 0.064377516497364], [0.0, 0.0, 0.0], [0.0, 0.039838727472789354, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.04822582799337658, 0.0], [0.0, 0.0, 0.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the cosine similarity for document 1 and document 2\n",
        "doc1_vector = document_vectors[0]\n",
        "doc2_vector = document_vectors[1]\n",
        "print(doc1_vector)\n",
        "print(doc2_vector)\n",
        "\n",
        "dot_product = np.dot(doc1_vector, doc2_vector)\n",
        "norm1 = np.linalg.norm(doc1_vector)\n",
        "norm2 = np.linalg.norm(doc2_vector)\n",
        "cosine_similarity = dot_product / (norm1 * norm2)\n",
        "print(cosine_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COWA6_6EY1YE",
        "outputId": "39b76a0b-f786-446e-b51e-317ea3561758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.03817878049475646, 0.0670599130180875]\n",
            "[0.0, 0.07330325854993242, 0.064377516497364]\n",
            "0.9452034609448741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing K-Means"
      ],
      "metadata": {
        "id": "TtBGkcEBgIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose number of clusters\n",
        "num_clusters = 3\n",
        "\n",
        "# document names\n",
        "doc_names = ['Bridget Jones', 'The Notebook', 'The Dark Knight', 'Titanic', 'Iron Man', 'Toy Story', 'Ratatouille', 'Frozen', 'Harry Potter', 'Back to the Future']\n",
        "\n",
        "# Run K-Means clustering\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(document_vectors)\n",
        "# Get cluster labels\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Print document name + cluster assignment\n",
        "for doc_name, label in zip(doc_names, labels):\n",
        "    print(f\"{doc_name} is in cluster {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-li6b3zZy1i",
        "outputId": "e53fa6c9-be9f-468b-c312-e48b790f74b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bridget Jones is in cluster 2\n",
            "The Notebook is in cluster 2\n",
            "The Dark Knight is in cluster 1\n",
            "Titanic is in cluster 0\n",
            "Iron Man is in cluster 1\n",
            "Toy Story is in cluster 1\n",
            "Ratatouille is in cluster 1\n",
            "Frozen is in cluster 1\n",
            "Harry Potter is in cluster 0\n",
            "Back to the Future is in cluster 1\n"
          ]
        }
      ]
    }
  ]
}